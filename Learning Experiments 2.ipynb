{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b42a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import random\n",
    "from random import randint\n",
    "import itertools\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "from sklearn.manifold import TSNE\n",
    "import sklearn.cluster\n",
    "\n",
    "import cv2\n",
    "\n",
    "import kornia\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision as tv\n",
    "from torchvision.models import resnet50, ResNet50_Weights, resnet34\n",
    "from torchvision.transforms import functional as tfunc\n",
    "\n",
    "sys.path.append('../mine_soar')\n",
    "import MalmoPython\n",
    "from utils import draw_image, draw_layers, MinecraftHandler\n",
    "\n",
    "MISSION_PORT = 9001\n",
    "VIDEO_SHAPE = (128, 128)\n",
    "VIDEO_DEPTH = 3\n",
    "DEVICE = 'cuda:0'\n",
    "# DEVICE = 'cpu'\n",
    "\n",
    "mc_handler = MinecraftHandler(VIDEO_SHAPE)\n",
    "\n",
    "def start_mission(file=\"random_world.xml\", seed=b''):\n",
    "    mc_handler.start_mission(file, seed)\n",
    "\n",
    "def get_mc_img(show=False):\n",
    "    image = mc_handler.get_image()\n",
    "    \n",
    "    if show:\n",
    "        draw_image(image, show=True)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab488962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, in_dims, mid_dims, out_dims, padding=\"zeros\", downscale=False, upscale=False, non_linearity=nn.ReLU):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.downscale = downscale\n",
    "        self.upscale = upscale\n",
    "        \n",
    "        if downscale:\n",
    "            self.downscale_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_dims, in_dims, 3, 2, 1, padding_mode=padding),\n",
    "                nn.BatchNorm2d(in_dims),\n",
    "                non_linearity()\n",
    "            )\n",
    "            \n",
    "        self.dim_compress = nn.Sequential(\n",
    "            nn.Conv2d(in_dims, mid_dims, 1, 1, 0),\n",
    "            nn.BatchNorm2d(mid_dims),\n",
    "            non_linearity()\n",
    "        )\n",
    "        \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(mid_dims, mid_dims, 5, 1, 2, padding_mode=padding),\n",
    "            nn.BatchNorm2d(mid_dims),\n",
    "            non_linearity()\n",
    "        )\n",
    "        \n",
    "        self.dim_extend = nn.Sequential(\n",
    "            nn.Conv2d(mid_dims, out_dims, 1, 1, 0),\n",
    "            nn.BatchNorm2d(out_dims),\n",
    "            non_linearity()\n",
    "        )\n",
    "        \n",
    "        if upscale:\n",
    "            self.upscale_layer = nn.Sequential(\n",
    "                nn.ConvTranspose2d(out_dims, out_dims, 2, 2, 0),\n",
    "                nn.BatchNorm2d(out_dims),\n",
    "                non_linearity()\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.downscale:\n",
    "            x = self.downscale_layer(x)\n",
    "        x = self.dim_compress(x)\n",
    "        x = self.bottleneck(x)\n",
    "        x = self.dim_extend(x)\n",
    "        if self.upscale:\n",
    "            x = self.upscale_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f54bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[[64,32,128], [128, 64, 256]], downscales=[True, False],\n",
    "                 padding=\"zeros\", non_linearity=nn.ReLU, final_nonlin=nn.Sigmoid,\n",
    "                 loss_fn=nn.MSELoss(), opt_method=torch.optim.SGD, lr=1e-3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.intake = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features[0][0], 1, 1, 0, padding_mode=padding),\n",
    "            nn.BatchNorm2d(features[0][0]),\n",
    "            non_linearity()\n",
    "        )\n",
    "        \n",
    "        compress_layers = []\n",
    "        for i, num_feats in enumerate(features):\n",
    "            if isinstance(num_feats, int):\n",
    "                in_feats = mid_feats = out_feats = num_feats\n",
    "            else:\n",
    "                in_feats = num_feats[0]\n",
    "                mid_feats = num_feats[1]\n",
    "                out_feats = num_feats[2]\n",
    "            layer = BottleneckBlock(in_feats, mid_feats, out_feats, \n",
    "                                    padding=padding, non_linearity=non_linearity, \n",
    "                                    downscale=downscales[i])\n",
    "            compress_layers.append(layer)\n",
    "        self.compress = nn.Sequential(*compress_layers)\n",
    "        \n",
    "        decompress_layers = []\n",
    "        for i, num_feats in enumerate(reversed(features)):\n",
    "            if isinstance(num_feats, int):\n",
    "                in_feats = mid_feats = out_feats = num_feats\n",
    "            else:\n",
    "                in_feats = num_feats[2]\n",
    "                mid_feats = num_feats[1]\n",
    "                out_feats = num_feats[0]\n",
    "            layer = BottleneckBlock(in_feats, mid_feats, out_feats, \n",
    "                                    padding=padding, non_linearity=non_linearity, \n",
    "                                    upscale=downscales[-i])\n",
    "            decompress_layers.append(layer)\n",
    "        self.decompress = nn.Sequential(*decompress_layers)\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(features[0][0], in_channels, 1, 1, 0, padding_mode=padding),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            final_nonlin()\n",
    "        )\n",
    "        \n",
    "        self.in_channels=in_channels\n",
    "        self.features = features\n",
    "        self.downscales = downscales\n",
    "        self.padding = padding\n",
    "        self.non_linearity = non_linearity\n",
    "        self.final_nonlin = final_nonlin\n",
    "        self.loss_fn = loss_fn\n",
    "        self.opt_method = opt_method\n",
    "        self.lr = lr\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.intake(x)\n",
    "        y = self.compress(y)\n",
    "        y = self.decompress(y)\n",
    "        y = self.output(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_models(in_channels=[3], \n",
    "                    features=[[[64,32,128], [128,64,256]]], \n",
    "                    downscales=[True, False],\n",
    "                    padding=[\"replicate\"],\n",
    "                    non_linearity=[nn.LeakyReLU],\n",
    "                    final_nonlin=[nn.Sigmoid],\n",
    "                    loss_fn=[nn.MSELoss()], \n",
    "                    opt_method=[torch.optim.SGD], \n",
    "                    lr=[1e-3]):\n",
    "    hyperparam_product = itertools.product(in_channels, features, downscales, padding, non_linearity, final_nonlin, loss_fn, opt_method, lr)\n",
    "    \n",
    "    for hparamset in hyperparam_product:\n",
    "        yield TestModel(*hparamset).to(DEVICE).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3801ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(models, iters=10001, show_step=250, save_step=250, reset_step=250, seed=2):\n",
    "    random.seed(seed)\n",
    "    \n",
    "    model_optims = [m.opt_method(m.parameters(), lr=m.lr) for m in models]\n",
    "\n",
    "    if not mc_handler.is_running:\n",
    "        start_mission(seed=random.randbytes(16))\n",
    "\n",
    "    session_id = f\"{datetime.strftime(datetime.now(), '%Y-%m-%d_%H-%M-%S')}\"\n",
    "    save_root = Path(\"./runs/\"+session_id+\"/\")\n",
    "    save_root.mkdir()\n",
    "\n",
    "    losses_record = []\n",
    "    images_record = []\n",
    "\n",
    "    try:\n",
    "        for i in range(iters):\n",
    "            mc_handler.sendCommand(f\"setYaw {(i*(359/reset_step))%360}\")\n",
    "            try:\n",
    "                img_tens = get_mc_img(False)\n",
    "                img_tens = img_tens.to(DEVICE)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                start_mission()\n",
    "                continue\n",
    "\n",
    "            models_out = [m(img_tens) for m in models]\n",
    "            losses = [models[i].loss_fn(img_tens, models_out[i]) for i in range(len(models))]\n",
    "            for loss in losses:\n",
    "                loss.backward()\n",
    "            for model_optim in model_optims:\n",
    "                model_optim.step()\n",
    "                model_optim.zero_grad()\n",
    "\n",
    "            losses_record.append([loss.item() for loss in losses])\n",
    "            if i % reset_step == 1:\n",
    "                print(f\"{i}: {[loss.item() for loss in losses]}\")\n",
    "    #             image = torch.concat([img_tens, *models_out], dim=3)\n",
    "                images = [img_tens, *models_out]\n",
    "                images = [i.squeeze() for i in images]\n",
    "                grid_image = vutils.make_grid(images, nrow=int((len(models)+1)**0.5), padding=0, pad_value=0.5, normalize=True).cpu()\n",
    "                draw_image(grid_image, show=True)\n",
    "                images_record.append([i.detach().cpu().squeeze() for i in images])\n",
    "\n",
    "            if i % show_step == 0:\n",
    "                print(f\"{i}: {[loss.item() for loss in losses]}\")\n",
    "    #             image = torch.concat([img_tens, *models_out], dim=3)\n",
    "                images = [img_tens, *models_out]\n",
    "                images = [i.squeeze() for i in images]\n",
    "                grid_image = vutils.make_grid(images, nrow=int((len(models)+1)**0.5), padding=0, pad_value=0.5, normalize=True).cpu()\n",
    "                draw_image(grid_image, show=True)\n",
    "                images_record.append([i.detach().cpu().squeeze() for i in images])\n",
    "            if reset_step is not None and i % reset_step == 0 and i > 0 and i != iters-1:\n",
    "                mc_handler.sendCommand(\"quit\")\n",
    "                start_mission(seed=random.randbytes(16))\n",
    "    except KeyboardInterrupt as e:\n",
    "        print(e)\n",
    "\n",
    "    with open(save_root.joinpath(\"losses.csv\"), \"w\") as csv_file:\n",
    "        for i, losses in enumerate(losses_record):\n",
    "            csv_file.write(f\"{i}{','.join([str(l) for l in losses])},\\n\")\n",
    "    for i, imgs in enumerate(images_record):\n",
    "        for j, img in enumerate(imgs):\n",
    "            draw_image(img, save_root.joinpath(f\"images_{i*show_step}_{j}.png\"))\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(losses_record)\n",
    "    plt.savefig(save_root.joinpath(\"losses.png\"))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    for i, model in enumerate(models):\n",
    "        with open(save_root.joinpath(f\"model_{i}.txt\"), \"w\") as model_file:\n",
    "            model_file.write(str(model))\n",
    "        with open(save_root.joinpath(f\"hparams_{i}.txt\"), \"w\") as model_file:\n",
    "            model_file.write(f\"in_channels={model.in_channels}\\n\")\n",
    "            model_file.write(f\"features={model.features}\\n\")\n",
    "            model_file.write(f\"downscales={model.downscales}\\n\")\n",
    "            model_file.write(f\"padding={model.padding}\\n\")\n",
    "            model_file.write(f\"non_linearity={model.non_linearity}\\n\")\n",
    "            model_file.write(f\"final_nonlin={model.final_nonlin}\\n\")\n",
    "            model_file.write(f\"loss_fn={model.loss_fn}\\n\")\n",
    "            model_file.write(f\"opt_method={model.opt_method}\\n\")\n",
    "            model_file.write(f\"lr={model.lr}\")\n",
    "\n",
    "    mc_handler.sendCommand(\"quit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ad777",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "in_channels=3, \n",
    "features=[\n",
    "#     [[32, 16, 64], [64, 32, 128]],\n",
    "    [[64, 32, 128], [128, 64, 256]]\n",
    "]\n",
    "downscales=[\n",
    "#     [False, False],\n",
    "    [True, False],\n",
    "#     [True, True]\n",
    "]\n",
    "padding=[\n",
    "#     \"zeros\",\n",
    "    \"replicate\",\n",
    "#     \"reflect\",\n",
    "#     \"circular\"\n",
    "]\n",
    "non_linearity=[\n",
    "    nn.LeakyReLU,\n",
    "]\n",
    "final_nonlin=[\n",
    "    nn.Sigmoid\n",
    "]\n",
    "img_transforms=[\n",
    "    None,\n",
    "]\n",
    "loss_fn=[\n",
    "    nn.MSELoss(),\n",
    "]\n",
    "opt_method=[\n",
    "    torch.optim.Adagrad\n",
    "]\n",
    "lr=[\n",
    "    1e-3\n",
    "]\n",
    "\n",
    "seed = random.randint(0, 2**16)\n",
    "models = gen_test_models(in_channels=in_channels, \n",
    "                         features=features, \n",
    "                         downscales=downscales,\n",
    "                         padding=padding,\n",
    "                         non_linearity=non_linearity,\n",
    "                         final_nonlin=final_nonlin,\n",
    "                         loss_fn=loss_fn,\n",
    "                         opt_method=opt_method,\n",
    "                         lr=lr)\n",
    "print(seed)\n",
    "test_model(list(models), iters=5001, reset_step=250, show_step=50, seed=seed)\n",
    "# for m in models\n",
    "#     print(f\"in_channels={m.in_channels}\")\n",
    "#     print(f\"features={m.features}\")\n",
    "#     print(f\"padding={m.padding}\")\n",
    "#     print(f\"non_linearity={m.non_linearity}\")\n",
    "#     print(f\"final_nonlin={m.final_nonlin}\")\n",
    "#     print(f\"img_transforms={m.img_transforms}\")\n",
    "#     print(f\"loss_fn={m.loss_fn}\")\n",
    "#     print(f\"opt_method={m.opt_method}\")\n",
    "#     print(f\"lr={m.lr}\")\n",
    "#     test_model(m, img_transforms=m.img_transforms, iters=2501)\n",
    "\n",
    "#     m.cpu()\n",
    "#     del m\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af5731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e04a5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
